# LLM-Research

This repository contains implementations of the concepts discussed in the PDF "Understanding Large Language Models: A Tutorial - Part 1" by Kenneth Zhang. The goal of this repository is to provide practical examples of how to apply the concepts discussed in the tutorial.

## Contents

The repository contains the following implementations:

- **Word Embeddings**: An implementation of word embeddings using the Skip-Gram model with Negative Sampling (SGNS) algorithm. This implementation shows how to train word embeddings on a corpus of text and how to use them to perform word similarity tasks.

- **BERT**: An implementation of the BERT model for sentence classification. This implementation shows how to fine-tune a pre-trained BERT model on a specific task and how to use it to make predictions on new data.

## Requirements

The implementations in this repository require the following libraries:

- PyTorch
- NumPy
- Pandas
- Scikit-learn

## Usage

Each implementation is contained in a separate directory and comes with its own README file that explains how to run the code and provides examples of how to use it.

## Contributing

Contributions to this repository are welcome. If you find a bug or have an idea for a new implementation, please open an issue or submit a pull request.

## License

This repository is licensed under the MIT License. See the LICENSE file for more information.
